<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>LIN 313 Language and Computers</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload lin313-page">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">About</a></li>
							<li><a href="publications.html">Publications</a></li>
							<li><a href="cv.html">CV</a></li>
							<li class="active"><a href="lin313.html">LIN 313</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<h1> UT Austin LIN 313: <br />Language and Computers<br />Fall 2025</h1>
									<p>A humanist introduction to computational linguistics and natural language processing</p>
								</header>

								<!-- Spring 2025 -->
								<section>
									<div class="row">
										<div class="col-6 col-12-small">
											<p><strong>Instructor:</strong> Gabriella Chronis (she/her)<br />
											<strong>Email:</strong> <a href="mailto:gsc685@my.utexas.edu">gsc685@my.utexas.edu</a><br />
											<strong>Meeting times:</strong> MWF 12:00pm-1:00pm<br />
											<strong>Location:</strong> RLP 1.104<br />
											<strong>Office hours:</strong> Wednesday, 2-3pm <br />
											<strong>Office:</strong> RLP 4th floor - East Cubicles</p>
										</div>
										<div class="col-6 col-12-small">
											<p><strong>TA:</strong> Sooji Lee <br />
											<strong>TA Email:</strong> <a href="mailto:sl55878@my.utexas.edu">sl55878@my.utexas.edu</a><br />
											<strong>TA Office Hours:</strong> Tuesday 9:30-10:30am, Thursday 2-3pm<br />
											<strong>TA Office:</strong> RLP 4th floor - East Cubicles</p>
										</div>
									</div>
								</section>

								<!-- Course Summary -->
								<section class="box">
									<header>
										<h2>Course Summary</h2>
									</header>
									<p>
										What is ChatGPT doing under the hood? How do Large Language Models work? What are they capable of? What are their potential pitfalls and even dangers? In this course, Our goal will be to gain a high-level understanding of contemporary language technologies. Through critical inquiry, example-based learning, and hands-on investigation, we will find insight into the fundamentals of how computers are used to represent, process, and produce natural language text and speech. We will cover the theory and practice of human language technology. Topics include statistical (pre neural networks) language models, vector semantics, machine learning for classification, AI and education, and other topics determined by student interest. By the second half of the semester, armed with the basic principles of text processing, we will be ready to tackle LLMs. <strong>Class Project:</strong> Throughout the semester, we will work towards building our own classification dataset and use this dataset to train and evaluate a model for a task we design together.<br />
<br />
This is NOT a coding course. There are NO math pre-requisites; we will cover the basics in probability and linear algebra that the course requires. (Linear algebra is just arithmetic with batches of numbers at a time). We will pay special attention to the human side of language technologies: the pragmatics of interaction, the relation between culture and language.<br />
<br />
However, the course goes beyond merely using AI systems. It emphasizes analysis and reasoning to draw and argue for valid conclusions about the design, capabilities and behavior of natural language systems. A foundation of computational and logical thinking skills is invaluable for understanding the human side of technologies. Demystifying AI is the first step in understanding ourselves to be subjects capable of transforming a world increasingly saturated with AI, rather than just consumers of AI. Therefore, assignments and assessments are designed to build basic skills in formal and computational analysis. The course philosophy is to ground abstract concepts in real world examples. Evaluation will be based on the midterm, homeworks, participation, and discussion questions.<br />
<br />
Before the flag system was abolished, this class had a quantitative reasoning flag. However, this is no longer a strict requirement. If you want to read ten books and write a research paper about the environmental and economic impacts of building AI data centers in Texas, (or build a program to rewrite song lyrics based on craigslist ads), go for it! I will support self-guided projects as best I can. Together, we can figure out a plan to measure progress towards a goal you want to work towards.
									</p>
								</section>

								<!-- Course Objectives -->
								<section>
									<header>
										<h2>Learning Outcomes</h2>
									</header>
									<p>By the end of this course, students will be able to:</p>
									<ul>
										<li><strong>You will be able to explain what kinds of problems have to be solved in order for computers to do useful things with language.</strong> In order to train a computer to perform a human language task, we first have to understand something about how human language works and what kinds of problems need to be solved.</li>
										<li><strong>You will learn how to approach tasks from a computational perspective.</strong> This is not a programming class, but through class exercises and homework, you will gain experience thinking like a computer scientist and about how a computer scientist would go about solving problems in human language.</li>
										<li><strong>You will gain insight into the technology that underlies a wide variety of human language technologies, from spell checkers to search engines to dialogue systems.</strong></li>
										<li><strong>You will gain experience thinking about data.</strong> Data science is one of the fastest growing fields for graduating college students. Throughout this class, we will think about the nature of experiments and data.</li>
										<li><strong>You will gain a better understanding of the ethical considerations around work in computational linguistics.</strong> We will spend time not just on the primary research, but on thinking about the higher-order ethical and practical considerations that impact computational linguistics as a field.</li>
									</ul>
								</section>

								<!-- Important Links -->
								<section>
									<header>
										<h2>Important Links</h2>
									</header>
									<ul>
										<li><a href="https://utexas.instructure.com/courses/1423946" target="_blank">Class Canvas page</a></li>
										<li><a href="https://www.are.na/gabriella-chronis/language-and-computers" target="_blank">Class inspiration page</a></li>
										<li><a href="https://polls.la.utexas.edu/course/5422/student" target="_blank">UT Instapoll</a></li>
										<li><a href="https://sage.eta.its.utexas.edu/tutors/9ceeff70-7172-4be5-b23e-515cbdae0dd5/sessions" target="_blank">Sage Tutor</a></li>
										<li><a href="https://www.cs.utexas.edu/forum-for-ai" target="_blank">UT Forum for AI (FAI): Upcoming talks</a></li>
										<li><a href="lin313/concept_map.html" target="_blank">Class Concept Map</a></li>
									</ul>
								</section>

								<!-- Readings -->
								<section>
									<header>
										<h2>Readings</h2>
									</header>
									<p>Readings will draw from various sources. Everything will be digitally available through Canvas, the UT library, or this website. We will draw pretty heavily from two books in particular.</p>
									<ul>
										<li><strong><a href="https://utexas.instructure.com/courses/1423946/files/folder/Readings?preview=85875091" target="_blank">Artificial Intelligence: A Guide for Humans</a></strong> (Farrar Girou, & Strauss 2019) by cognitive scientist Melanie Mitchell (Santa Fe Institute). A very accessible, math-free introduction to AI that doesn't shy away from the details. Published just shy of the LLM era, it's a prescient foretelling of what was to come. It grounds the discourse around the present 'AI Spring' in a century of boom and bust cycles and connects today's questions to long-running debates about the nature of human intelligence.</li>
										<li><strong><a href="https://web.stanford.edu/~jurafsky/slp3/ed3book_Jan25.pdf" target="_blank">Speech and Language Processing</a></strong> By Dan Jurafsky and James Martin (UC Boulder). The current gold standard NLP textbook.  This text is written for computer science students. It is dense, and gets technical at times. Therefore, where Mitchell covers a topic I will assign that chapter instead, (but I'll still link you to J&M for optional further reading.<strong> Note:</strong> Make sure you use the copy I link you to which is the most up to date draft of 3rd edition.</li>	
									</ul>
									<p>The 'math free' Mitchell isn't dumbed downâ€“it's deeper. Mitchell's ability to explain technical topics without resorting to esoteric symbols and formalisms is rare and invaluable. The more you (as a student) are able to explain technical topics in terms of concrete examples and experience, the stronger the foundation of intuition you build, and the better you are set up for creative reasoning about those topics. Use the mitchell to understand what is happening. Use J&M for nuts and bolts. </br>
										</p>
								</section>

								<!--Additional Resources
								<section>
									<header>
										<h4>Additional Resources</h4>
									</header>
									<ul>
										<li><a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOaMFbaqxPDoLWjDaRAdP9D" target="_blank">Stanford CS224N: NLP with Deep Learning</a></li>
										<li>God Human Animal Machine</li>
									</ul>
								</section>
								-->



								<!-- Schedule -->
								<section>
									<header>
										<h2>Course Schedule</h2>
									</header>

									<p>***The schedule changes frequently. Check this page regularly for updates.***</p>
									
									<h3>Unit 1: Language as Information</h3>
									<div class="table-wrapper">
										<table>
											<thead>
												<tr>
													<th>Date</th>
													<th>Before Class</th>
													<th>Topic</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td colspan="3"><strong>Week 1: Math, grammar, and dramatic social transformation walk into a bar </strong></td>
												</tr>
												<tr>
													<td>Mon 8/25</td>
													<td>
													</td>
													<td>Naive Bayes for sentiment classification <a href="documents/lin_313_fa_2025/slides/lin_f313_fa2025_lec_1_sentiment_analysis.pdf" target="_blank">(slides)</a> <a href="documents/lin_313_fa_2025/handouts/8_24_2025_naive_bayes.pdf" target="_blank">(handout)</a></td>
												</tr>
												<tr>
													<td>Wed 8/27</td>
													<td>
													Syllabus<br />
													<a href="https://www.anthropic.com/news/golden-gate-claude" target="_blank">Golden Gate Claude (3 mins)</a><br />
													<a href="https://www.youtube.com/watch?v=BUqGH2IwmOw" target="_blank">Video: How do you like them owls? Subliminal Messaging LLMs (15 mins)</a><br />
													<a href="https://alignment.anthropic.com/2025/subliminal-learning/" target="_blank">Optional: original blog post</a><br />
													<a href="https://subliminalquiz.streamlit.app/" target="_blank">Optional: take the owl quiz!</a></td>
													<td>Course introduction & developing a thematics <a href="documents/lin_313_fa_2025/handouts/8_27_25_developing_a_thematics.pdf" target="_blank">(handout)</a></td>
												</tr>
												<tr>
													<td>Fri 8/29</td>
													<td><a href="https://web.archive.org/web/20120312201453/https://www.nytimes.com/2010/01/31/magazine/31FOB-onlanguage-t.html" target="_blank">Crash Blossoms (5 mins)</a><br/>
														Elaine Rich, Alan Kaylor Cline <a href="https://www.cs.utexas.edu/~dnp/frege/subsection-178.html" target="_blank">Reasoning: an introduction to Logic, Sets, Functions: Chapter 7.2 (specifically 7.2.2, 7.2.3, 7.2.5, 7.2.7, 7.2.8)</a><br />
													</td>
													<td>Syntax, semantics, and ambiguity <a href="documents/lin_313_fa_2025/slides/8_29_2025_syntax_semantic_ambiguity.pdf" target="_blank">(slides)</a></td>
												</tr>
												<tr>
													<td colspan="3"><strong>Week 2: Linguistic Fundamentals</strong></td>
												</tr>
												<tr>
													<td>Mon 9/1</td>
													<td></td>
													<td>Labor Day - No Class</td>
												</tr>
												<tr>
													<td>Wed 9/3</td>
													<td>Mitchell, Prologue & Ch. 1 "The Roots of Information" (focus on Ch. 1) <a href="https://utexas.instructure.com/courses/1423946/files/folder/Readings" target="_blank">(on Canvas)</a></td>
													<td>Why is AI so obsessed with language? <a href="documents/lin_313_fa_2025/slides/9_3_2025_whats_special_about_language.pdf" target="_blank">(slides)</a></td>
												</tr>
												<tr>
													<td>Fri 9/5</td>
													<td></td>
													<td>Limits of the symbolic approach <a href="documents/lin_313_fa_2025/slides/9_5_20203_limits_of_symbolic_models.pdf" target="_blank">(slides)</a></td>
												</tr>
												<tr>
													<td colspan="3"><strong>Week 3: What the #%!@& is a language model anyway</strong></td>
												</tr>
												<tr>
													<td>Mon 9/8</td>
													<td>
														<a href="https://www.youtube.com/watch?v=D7B17klZmAU" target="_blank">Video: probability (Day 1 review)</a></br>
														<a href="https://github.com/deepmay/DM23-ml-for-monsters/blob/main/notebooks/day2_probability_students.ipynb" target="_blank">Conditional probability</a></br>
														<a href="https://github.com/deepmay/DM23-ml-for-monsters/blob/main/notebooks/day2_probability.ipynb" target="_blank">(Same notebook with prompt questions answered)</a></br>
													</td>
													<td>Introduction to N-gram Language Models <a href="documents/lin_313_fa_2025/slides/9_8_ngram_language_models.pdf" target="_blank">(slides)</a> <a href="dice-roller.html" target="_blank">(dice roller)</a> <a href="documents/lin_313_fa_2025/handouts/9_8_2025_distributions.pdf" target="_blank">(handout)</a></td>


												</tr>
												<tr>
													<td>Wed 9/10</td>
													<td>
														Reading from Jurafsky &amp; Martin: <a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf" target="_blank">pp. 1-10</a></br>
														Optional: <a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf" target="_blank">Finish Jurafsky Chapter</a>. Note that it gets technical!</br>
														Optional video: <a href="https://www.youtube.com/watch?v=GiyMGBuu45w" target="_blank">Anna Potapenko, Undersanding N-gram models</a></br>
													</td>
													<td>N-gram models continued <a href="documents/lin_313_fa_2025/slides/9_10_2025_ngram_language_models_part_2.pdf" target="_blank">(slides)</a> <a href="conditional-dice.html" target="_blank">(conditional dice)</a></td>													

												</tr>
												<tr>
													<td>Fri 9/12</td>
													<td>
														<strong>Homework 1 Due</strong><br/>
														Jurafsky & Martin 2.3 "Corpora" (pp. 16-17)<br/>
														Optional video: <a href="https://www.youtube.com/watch?v=KZeIEiBrT_w" target="_blank">The Strange Math that Predicts (almost) anything</a></td>
													<td>Building and testing our own N-Gram Model <a href="n-gram-models.html" target="_blank">(N-gram Generator)</a> <a href="documents/lin_313_fa_2025/slides/9_12_25_n_gram_language_models_part_3.pdf" target="_blank">(slides)</a></td>
												</tr>
											</tbody>
										</table>
									</div>

									<h3>Unit 2: Meaning & Classification </h3>
									<div class="table-wrapper">
										<table>
											<thead>
												<tr>
													<th>Date</th>
													<th>Before Class</th>
													<th>Topic</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td colspan="3"><strong>Week 4: Signs & Society</strong></td>
												</tr>
												<tr>
													<td>Mon 9/15</td>
													<td>
															<a href="https://utexas.instructure.com/courses/1423946/assignments/7347116" target="_blank">Courtney Handman, 2025. "The Chatbot's True Self"</a><br />
															<strong>Social Annotations in Canvas with Perusall</strong><br/>
													</td>
													<td>Paper Discussion <a href="documents/lin_313_fa_2025/handouts/9_15_2025_chatbots_true_self.pdf" target="_blank">(handout)</a></td>

												</tr>
												<tr>
													<td>Wed 9/17</td>
													<td><a href="https://www.youtube.com/watch?v=IJEaMtNN_dM&t=25s" target="_blank">Video: Tom Scott, The Hidden Rules of Conversation</a><br />
														<a href="documents/lin313_readings/rich_and_cline_reasoning_chapter_7_english_into_logic.pdf" target="_blank">Elaine Rich and Alan Kline. Reasoning. Chapter 7.3 (pp. 31-37, 40-41)</a><br />
													</td>
													<td>Semiotics & Discourse: The features of conversation <a href="documents/lin_313_fa_2025/slides/9_17_2025_discourse.pdf" target="_blank">(slides)</a></td>
												</tr>
												<tr>
													<td>Fri 9/19</td>
													<td>
														<a href="https://www.anthropic.com/news/mapping-mind-language-model?trk=public_post_comment-text" target="_blank">Anthropic Blog. "Mapping the Mind of a Large Large Language Model" (10 mins)</a><br />
														<a href="https://transformer-circuits.pub/2024/scaling-monosemanticity/features/index.html" target="_blank">Optional: Interactive LLM Feature Browser</a><br />
														<a href="https://distill.pub/2019/activation-atlas/" target="_blank">Optional: Visual Feature Activation Atlas (for an image classifier)</a><br />
													</td>
													<td>Semiotics & Discourse II: The unwritten rules of conversation <a href="documents/lin_313_fa_2025/slides/9_19_2025_discourse_part_2.pdf" target="_blank">(slides)</a></td>

												</tr>
												<tr>
													<td colspan="3"><strong>Week 5: Text Classification</strong></td>
												</tr>
												<tr>
													<td>Mon 9/22</td>
													<td><a href="https://utexas.instructure.com/courses/1423946/files/folder/Readings" target="_blank">DBM Ch. 5.1-5.5 Classifying documents (pp. 127-140)</a></td>
													<td>Features and Machine Learning Classification <a href="documents/lin_313_fa_2025/slides/9_22_25_machine_learning_systems.pdf" target="_blank">(slides)</a></td>

												</tr>
												<tr>
													<td>Wed 9/24</td>
													<td>
														<strong>Submit your text for the class corpus</strong><br/>
														<a href="https://utexas.instructure.com/courses/1423946/files/folder/Readings" target="_blank">DBM 5.5 (pp. (140-145) Especially Under the hood 9</a>
													</td>
													<td>Naive Bayes Again (and/or: classification in the wild) <a href="documents/lin_313_fa_2025/slides/9_24_25_machine_learning_systems_part_2_evaluation.pdf" target="_blank">(slides)</a></td>

												</tr>
												<tr>
													<td>Fri 9/26</td>
													<td>
														Bring your ideas to class!<br/>
														<a href="https://www.youtube.com/watch?v=qWfzIYCvBqo" target="_blank">Video: Precision & Recall (5mins)</a><br />
														<a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/" target="_blank">Optional: A Visual Introduction to Machine Learning (Part 1)</a><br />
														<a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-2/" target="_blank">Optional: A Visual Introduction to Machine Learning (Part 2)</a><br />
														<a href="https://www.youtube.com/watch?v=HZGCoVF3YvM" target="_blank">Optional Video: The Geometry of Changing Beliefs (15 mins)</a><br />

													</td>
													<td>Machine Learning Evaluation; Brainstorming class classification project <a href="documents/lin_313_fa_2025/slides/9_26_25_machine_learning_systems_part_3_evaluation_for_real.pdf" target="_blank">(slides)</a></td>
												</tr>
												<tr>
													<td colspan="3"><strong>Week 6: Data</strong></td>
												</tr>
												<tr>
													<td>Mon 9/29</td>
													<td><strong>Homework 2 due</strong><br/>
													<td>
														Inter-annotator agreement 
														<a href="documents/lin_313_fa_2025/slides/9_29_2025_interannotator_agreement.pdf" target="_blank">(slides)</a> 
														<a href="documents/lin_313_fa_2025/handouts/9_29_2025_inter_annotator_agreement.pdf" target="_blank">(handout)</a>
														<a href="documents/lin_313_fa_2025/handouts/9_29_25_potential_classification_schemes.pdf" target="_blank">(classifier ideas)</a>
													</td>



												</tr>
												<tr>
													<td>Wed 10/1</td>
													<td></td>
													<td>Round 1 Data annotation for class project
														<a href="documents/lin_313_fa_2025/slides/10_1_interannotator_agreement_part_2.pdf" target="_blank">(slides)</a>
														<a href="documents/lin_313_fa_2025/handouts/9_29_2025_inter_annotator_agreement.pdf" target="_blank">(handout [same as Mon])</a>

													</td>
												</tr>
												<tr>
													<td>Fri 10/3</td>
													<td>
															<a href="https://utexas.instructure.com/courses/1423946/assignments/7356461" target="_blank">Kate Crawford and Trevor Paglen. 2019. "Excavating AI"</a><br />
															<strong>Social Annotations in Canvas with Perusall</strong><br/>
													</td>	
													<strong>Social Annotations in Canvas with Perusall</strong><br/>

												</td>
													<td>Discussion: Excavating AI</td>
												</tr>
											</tbody>
										</table>
									</div>

									<h3>Unit 3: Neural Networks & Deep Learning</h3>
									<div class="table-wrapper">
										<table>
											<thead>
												<tr>
													<th>Date</th>
													<th>Before Class</th>
													<th>Topic</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td colspan="3"><strong>Week 7: Neural Networks</strong></td>
												</tr>
												<tr>
													<td>Mon 10/6</td>
													<td>

													</td>
													<td>
														Workshop on class project; <a href="https://utexas.instructure.com/courses/1423946/assignments/7342419" target="_blank"><strong>Submit Round 1 Annotations</strong></a><br/>
														<a href="documents/lin_313_fa_2025/handouts/9_29_2025_inter_annotator_agreement.pdf" target="_blank">(handout)</a>
														<a href="documents/lin_313_fa_2025/handouts/9_29_25_potential_classification_schemes.pdf" target="_blank">(classifier ideas)</a>
													</td>

												</tr>
												<tr>
													<td>Wed 10/8</td>
													<td>Mitchell, Ch. 1 pp 24-32 (Perceptrons) <a href="https://utexas.instructure.com/courses/1423946/files/folder/Readings" target="_blank">(on Canvas)</a><br/>
													<a href="https://web.stanford.edu/~jurafsky/slp3/ed3book_Jan25.pdf" target="_blank"> J&M 5.0-5.2 (please do look at this, but don't worry about understanding the details!)</a></td>

													<td>
														Vectors; The Perceptron/Logistic Regression
														<a href="documents/lin_313_fa_2025/slides/10_8_25_the_perceptron.pdf" target="_blank">(slides)</a>
														<a href="documents/lin_313_fa_2025/slides/annotated_10_8_25_the_perceptron.pdf" target="_blank">(slides-annotated)</a>
												
													</td>
												</tr>
												<tr>
													<td>Fri 10/10</td>
													<td><a href="https://www.youtube.com/watch?v=l-9ALe3U-Fg" target="_blank">Video: ChatGPT is made from 100 milion of these [The Perceptron](25 minutes)</a></td>

													<td>How Neural Networks Learn; The Perceptron Trick
														<a href="documents/lin_313_fa_2025/slides/10_10_25_the_perceptron_trick.pdf" target="_blank">(slides)</a>
														<a href="documents/lin_313_fa_2025/slides/annotated_10_10_25_the_perceptron_trick.pdf" target="_blank">(slides-annotated)</a>
												

													</td>
												</tr>
												<tr>
													<td colspan="3"><strong>Week 8: Deep Learning</strong></td>
												</tr>

												<tr>
													<td>Mon 10/13</td>
													<td> <a href="https://www.youtube.com/watch?v=hgWie9dnssU" target="_blank"> Video: The Curly Fry Conundrum (10 mins)</a>  </td>
													<td>Training a Neural Network <a href="documents/lin_313_fa_2025/slides/10_13_25_training_a_neural_network.pdf" target="_blank">(slides)</a></td>
												</tr>
												<tr>
													<td>Wed 10/15</td>
													<td>
														Mitchell Ch. 2: Neural Networks and the Ascent of Machine Learning <a href="https://utexas.instructure.com/courses/1423946/files/folder/Readings" target="_blank">(on Canvas)</a><br/>
														<strong>Homework 3 Due</strong><br/></td>
													<td>Multi-layer Perceptrons; Backpropagation intuition <a href="documents/lin_313_fa_2025/slides/10_15_25_multi_layer_neural_networks.pdf" target="_blank">(slides)</a></td>
												</tr>
												<tr>
													<td>Fri 10/17</td>
													<td></td>
													<td>In Class: Round 2 Annotations</td>
												</tr>
												<tr>
													<td colspan="3"><strong>Week 9: Midterm </strong></td>
												</tr>
												<tr>
													<td>Mon 10/20</td>
													<td></td>
													<td>Review <a href="documents/lin_313_fa_2025/handouts/10_20_2025_lin313_fall_2025_midterm_practice.pdf" target="_blank">(practice)</a></td>
												</tr>
												<tr>
													<td>Wed 10/22</td>
													<td>Studyyy</td>
													<td><strong>Midterm</strong></td>
												</tr>
												<tr>
													<td>Fri 10/24</td>
													<td></td>
													<td> In Class: More Round 2 Annotations </td>
												</tr>
											</tbody>
										</table>
									</div>

									<h3>Unit 4: Large Language Models & Society</h3>
									<div class="table-wrapper">
										<table>
											<thead>
												<tr>
													<th>Date</th>
													<th>Before Class</th>
													<th>Topic</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td colspan="3"><strong>Week 10: Word Embeddings </strong></td>
												</tr>
												<tr>
													<td>Mon 10/27</td>
													<td>
														Mitchell Ch. 11: Words, and the company they keep (through 'The semantic space of words') <br />
														J&M 6.0-6.3 (pp. 101-110)
													</td>

													<td>Word Vectors, a.k.a Distributional Semantic Space</td>
													<td></td>
												</tr>
												<tr>
													<td>Wed 10/29</td>
													<td>
														J&M 6.4 (optionally, through the end of the chapter)<br />
														<strong>Complete Round 3 Annotations on Label Studio</strong>
													</td>
													<td>Word Vectors II - Distance, Similarity, and Semantic Space</td>
													
												</tr>
												<tr>
													<td>Fri 10/31</td>
													<td><a href="https://dl-acm-org.ezproxy.lib.utexas.edu/doi/pdf/10.5555/3157382.3157584" target="_blank">Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings</a></td>
													<td>Discussion: Bias in Word Embeddings (exploring implicit associations)</td>
												</tr>
												<tr>
													<td colspan="3"><strong>Week 11: Transformers & LLMs</strong></td>
												</tr>
												<tr>
													<td>Mon 11/3</td>
													<td></td>
													<td>From BERT to GPT-3: The LLM Timeline</td>
												</tr>
												<tr>
													<td>Wed 11/5</td>
													<td><strong>Classifier Design Decisions</strong></td>
													<td>Training Large Language Models: Scale and Emergence</td>

												</tr>
												<tr>
													<td>Fri 11/7</td>
													<td></td>
													<td> The 'Chat' in ChatGPT: Reinforcement learning with human feedback</td>


												</tr>
												<tr>
													<td colspan="3"><strong>Week 12: Philosophy of Mind</strong></td>
												</tr>
												<tr>
													<td>Mon 11/10</td>
													<td></td>
													<td>Discussion: Revise our initial questions about LLMs</td>
												</tr>
												<tr>
													<td>Wed 11/12</td>
													<td><strong>Complete Round 4 Annotations on Label Studio</strong></td>

													<td>Chinese Room Argument / Libraries</td>
												</tr>
												<tr>
													<td>Fri 11/14</td>
													<td></td>
													<td>Truth, Hallucination</td>
												</tr>
												<tr>
													<td colspan="3"><strong>Week 13: Applications</strong></td>
												</tr>
												<tr>
													<td>Mon 11/17</td>
													<td></td>
													<td>TBD depending on student interests. Possible topics include  the politics of AI, style transfer/controlled generation, interpretability</td>
												</tr>
												<tr>
													<td>Wed 11/19</td>
													<td><strong>Homework 4 Due</strong></td>
													<td>TBD</td>
												</tr>
												<tr>
													<td>Fri 11/21</td>
													<td></td>
													<td>TBD</td>
												</tr>
												<tr>
													<td colspan="3"><strong>Week 14: Fall Break - No Class</strong></td>
												</tr>
												<tr>
													<td colspan="3"><strong>Week 15: Looking Forward</strong></td>
												</tr>
												<tr>
													<td>Mon 12/1</td>
													<td></td>
													<td>Latest Innovations: RAG and Chain of Thought</td>
												</tr>
												<tr>
													<td>Wed 12/3</td>
													<td><strong>Final Evaluations for class project</strong></td>
													<td>Guest Lecture from research scientist</td>
												</tr>
												<tr>
													<td>Fri 12/5</td>
													<td></td>
													<td>Panel Discussion: AI & the workplace</td>
												</tr>
											</tbody>
										</table>
									</div>

									<h3>Finals Week</h3>
									<div class="table-wrapper">
										<table>
											<thead>
												<tr>
													<th>Date</th>
													<th>Before Class</th>
													<th>Topic</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td colspan="3"><strong>Week 16: Finals Week</strong></td>
												</tr>
												<tr>
													<td>Mon 12/8</td>
													<td></td>
													<td>Final Reflections & Course Wrap-up</td>
												</tr>
												<tr>
													<td>Wed 12/10</td>
													<td></td>
													<td>Optional Review session</td>
												</tr>
												<tr>
													<td>TBD</td>
													<td></td>
													<td><strong>Final Exam</strong></td>
												</tr>
											</tbody>
										</table>
									</div>
								</section>

								<!-- Grading Breakdown -->
								<section>
									<header>
										<h2>Grading Breakdown</h2>
									</header>

									<p>Your final grade will be based on the following components. There will be ample opportunity throughout the semester to get extra credit in different ways: adding to the online discussion, attending some of the many AI talks that happen on campus, or working on an independent project.</p>
									
									<div class="table-wrapper">
										<table>
											<thead>
												<tr>
													<th>Assessment</th>
													<th>Points</th>
													<th>Description</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td><strong>Assignments</strong></td>
													<td>180</td>
													<td>Assignments synthesize quantitative topics with critical reflection.</td>
												</tr>
												<tr>
													<td><strong>Class Project</strong></td>
													<td>50</td>
													<td>Help build our state-of-the-art [?]-classifier</td>
												</tr>
												<tr>
													<td><strong>Midterm Exam</strong></td>
													<td>100</td>
													<td>In-class exam over Units 1-3</td>
												</tr>
												<tr>
													<td><strong>Final Exam</strong></td>
													<td>100</td>
													<td>Cumulative exam focusing on Unit 4 and synthesis</td>
												</tr>
												<tr>
													<td><strong>Participation & Quizzes</strong></td>
													<td>70</td>
													<td>Class participation, attendance, discussion posts, quizzes</td>
											</tbody>
											<tfoot>
												<tr>
													<td colspan="1"><strong>Total</strong></td>
													<td><strong>500</strong></td>
												</tr>
											</tfoot>
										</table>
									</div>
								</section>

								<!-- University Policies -->
								<section>
									<header>
										<h2>University Policies</h2>
									</header>
									<h3>Academic Integrity</h3>
									<p>Each student in the course is expected to abide by the University of Texas Honor Code: "As a student of The University of Texas at Austin, I shall abide by the core values of the University and uphold academic integrity." Plagiarism is taken very seriously at UT. Therefore, if you use words or ideas that are not your own (or that you have used in previous class), you must cite your sources. Otherwise you will be guilty of plagiarism and subject to academic disciplinary action, including failure of the course. You are responsible for understanding UT's Academic Honesty and the University Honor Code which can be found at the following web address: <a href="https://deanofstudents.utexas.edu/conduct/standardsofconduct.php" target="_blank">https://deanofstudents.utexas.edu/conduct/standardsofconduct.php</a></p>

									<h3>Sharing of Course Materials is Prohibited</h3>
									<p>No materials used in this class, including, but not limited to, lecture hand-outs, videos, assessments (quizzes, exams, papers, projects, homework assignments), in-class materials, review sheets, and additional problem sets, may be shared online or with anyone outside of the class unless you have my explicit, written permission. Unauthorized sharing of materials promotes cheating. It is a violation of the University's Student Honor Code and an act of academic dishonesty. I am well aware of the sites used for sharing materials, and any materials found online that are associated with you, or any suspected unauthorized sharing of materials, will be reported to Student Conduct and Academic Integrity in the Office of the Dean of Students. These reports can result in sanctions, including failure in the course.</p>

									<h3>Notice about missed work due to religious holy days</h3>
									<p>A student who misses an examination, work assignment, or other project due to the observance of a religious holy day will be given an opportunity to complete the work missed within a reasonable time after the absence, provided that he or she has properly notified the instructor. It is the policy of the University of Texas at Austin that the student must notify the instructor at least fourteen days prior to the classes scheduled on dates he or she will be absent to observe a religious holy day. For religious holy days that fall within the first two weeks of the semester, the notice should be given on the first day of the semester. The student will not be penalized for these excused absences, but the instructor may appropriately respond if the student fails to complete satisfactorily the missed assignment or examination within a reasonable time after the excused absence.</p>

									<h3>FERPA and Class Recordings</h3>
									<p>Class recordings are reserved only for students in this class for educational purposes and are protected under FERPA. The recordings should not be shared outside the class in any form. Violation of this restriction by a student could lead to Student Misconduct proceedings.</p>

									<h3>Academic dishonesty policy</h3>
									<p>You are encouraged to discuss assignments with classmates. But all written work must be your own. Students caught cheating will automatically fail the course. If in doubt, ask the instructor.</p>

								</section>

								<!-- Student Support Services -->
								<section>
									<header>
										<h2>Student Support Services</h2>
									</header>

									<h3>Services for Students with Disabilities</h3>
									<p>The university is committed to creating an accessible and inclusive learning environment consistent with university policy and federal and state law. Please let me know if you experience any barriers to learning so I can work with you to ensure you have equal opportunity to participate fully in this course. If you are a student with a disability, or think you may have a disability, and need accommodations please contact Services for Students with Disabilities (SSD). Please refer to SSD's website for contact and more information: <a href="http://diversity.utexas.edu/disability/" target="_blank">http://diversity.utexas.edu/disability/</a>. If you are already registered with SSD, please deliver your Accommodation Letter to me as early as possible in the semester so we can discuss your approved accommodations and needs in this course.</p>

									<h3>Counseling and Mental Health Center</h3>
									<p>The Counseling and Mental Health Center serves UT's diverse campus community by providing high quality, innovative and culturally informed mental health programs and services that enhance and support students' well-being, academic and life goals. To learn more about your counseling and mental health options, call CMHC at (512) 471-3515.</p>
									<p>If you are experiencing a mental health crisis, call the CMHC Crisis Line 24/7 at (512) 471-2255.</p>

									<h3>The Sanger Learning Center</h3>
									<p>Did you know that more than one-third of UT undergraduate students use the Sanger Learning Center each year to improve their academic performance? All students are welcome to take advantage of Sanger Center's classes and workshops, private learning specialist appointments, peer academic coaching, and tutoring for more than 70 courses in 15 different subject areas. For more information, please visit <a href="http://www.utexas.edu/ugs/slc" target="_blank">http://www.utexas.edu/ugs/slc</a> or call 512-471-3614 (JES A332).</p>

									<h3>Additional Resources</h3>
									<ul>
										<li>Undergraduate Writing Center: <a href="http://uwc.utexas.edu/" target="_blank">http://uwc.utexas.edu/</a></li>
										<li>Libraries: <a href="http://www.lib.utexas.edu/" target="_blank">http://www.lib.utexas.edu/</a></li>
										<li>ITS: <a href="http://www.utexas.edu/its/" target="_blank">http://www.utexas.edu/its/</a></li>
										<li>Emergency Services: <a href="http://deanofstudents.utexas.edu/emergency/" target="_blank">http://deanofstudents.utexas.edu/emergency/</a></li>
									</ul>
								</section>

							</section>

					</div>
					<div id="footer">
					</div>					
			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>